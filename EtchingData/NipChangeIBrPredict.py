import os
import joblib
import pandas as pd
import numpy as np
import warnings
import sys

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

warnings.filterwarnings('ignore')

# å¯¼å…¥Column Splitting2.pyä¸­çš„å‡½æ•°
try:
    from Column_Splitting2 import get_element_ratio

    print("âœ… æˆåŠŸå¯¼å…¥Column_Splitting2.pyä¸­çš„get_element_ratioå‡½æ•°")
except ImportError as e:
    print(f"âŒ å¯¼å…¥Column_Splitting2.pyå¤±è´¥: {e}")
    print("å°†ä½¿ç”¨å†…ç½®çš„ç®€åŒ–ç‰ˆæœ¬")


    # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬
    def get_element_ratio(composition):
        """
        ç®€åŒ–ç‰ˆçš„å…ƒç´ æ¯”ä¾‹è§£æå‡½æ•°
        """
        elements = {'Cs': 'A', 'MA': 'A', 'FA': 'A', 'Rb': 'A', 'Pb': 'B', 'Sn': 'B', 'I': 'X', 'Br': 'X', 'Cl': 'X'}
        element_ratio = {key: 0 for key in elements.keys()}

        # ç®€åŒ–è§£æé€»è¾‘
        try:
            if 'FA' in composition and 'MA' in composition:
                # ä»åŒ–å­¦å¼ä¸­æå–FAå’ŒMAçš„æ¯”ä¾‹
                fa_match = composition.split('FA')[-1].split(')')[0].split('MA')[0]
                ma_match = composition.split('MA')[-1].split(')')[0]

                try:
                    fa_ratio = float(fa_match) if fa_match.replace('.', '').isdigit() else 0.95
                    ma_ratio = float(ma_match) if ma_match.replace('.', '').isdigit() else 0.05
                except:
                    fa_ratio = 0.95
                    ma_ratio = 0.05
            else:
                fa_ratio = 0.95
                ma_ratio = 0.05

            # è®¾ç½®é»˜è®¤å€¼
            element_ratio['FA'] = fa_ratio
            element_ratio['MA'] = ma_ratio
            element_ratio['Cs'] = 0.05
            element_ratio['I'] = 0.98
            element_ratio['Br'] = 0.02
            element_ratio['Cl'] = 0.0
            element_ratio['Pb'] = 1.0

        except Exception as e:
            print(f"è§£æé’™é’›çŸ¿åŒ–å­¦å¼å¤±è´¥: {e}")

        return element_ratio


def parse_perovskite_composition(composition):
    """
    è§£æé’™é’›çŸ¿åŒ–å­¦å¼å¹¶è¿”å›å…ƒç´ æ¯”ä¾‹ - ä½¿ç”¨å¯¼å…¥çš„get_element_ratioå‡½æ•°
    """
    try:
        # å…ˆå¤„ç†ä¸€äº›å¸¸è§çš„æ ¼å¼é—®é¢˜
        composition = composition.replace('l', 'I')  # ä¿®æ­£å°å†™lä¸ºå¤§å†™I

        # ä½¿ç”¨å¯¼å…¥çš„get_element_ratioå‡½æ•°è¿›è¡Œè§£æ
        ratio = get_element_ratio(composition)

        # ç¡®ä¿æ‰€æœ‰å¿…éœ€çš„å…ƒç´ éƒ½æœ‰å€¼
        required_elements = ['Cs', 'MA', 'FA', 'I', 'Br', 'Cl', 'Pb']
        for element in required_elements:
            if element not in ratio:
                ratio[element] = 0.0

        return ratio
    except Exception as e:
        print(f"è§£æé’™é’›çŸ¿åŒ–å­¦å¼å¤±è´¥: {composition}, é”™è¯¯: {e}")
        # è¿”å›é»˜è®¤å€¼
        return {'Cs': 0.0, 'MA': 0.0, 'FA': 0.0, 'I': 0.0, 'Br': 0.0, 'Cl': 0.0, 'Pb': 1.0}


def encode_categorical_features(df, mapping_df):
    """
    å¯¹åˆ†ç±»ç‰¹å¾è¿›è¡Œç¼–ç 
    """
    encoded_df = df.copy()
    categorical_features = [
        'Structure', 'HTL', 'HTL-2', 'HTL_Passivator', 'HTL-Addictive',
        'ETL', 'ETL-2', 'ETL_Passivator', 'ETL-Addictive',
        'Metal_Electrode', 'Glass', 'Precursor_Solution',
        'Precursor_Solution_Addictive', 'Deposition_Method',
        'Antisolvent', 'Type', 'brand'
    ]

    for feature in categorical_features:
        if feature in encoded_df.columns:
            feature_mapping = mapping_df[mapping_df['Feature'] == feature]
            if len(feature_mapping) > 0:
                mapping_dict = dict(zip(feature_mapping['Original'], feature_mapping['Encoded']))
                original_value = encoded_df[feature].iloc[0]

                if original_value == '' or pd.isna(original_value):
                    empty_mapping = feature_mapping[feature_mapping['Original'].isna()]
                    encoded_value = empty_mapping['Encoded'].iloc[0] if len(empty_mapping) > 0 else 0
                else:
                    encoded_value = mapping_dict.get(original_value, 0)

                encoded_df[feature] = encoded_value
            else:
                encoded_df[feature] = 0

    return encoded_df


def predict_i_br_combinations():
    """
    åŸºäºç»™å®šçš„å®éªŒæ•°æ®ï¼Œé¢„æµ‹ä¸åŒIå’ŒBrç»„åˆçš„PCE
    """
    # æ¨¡å‹ä¿¡æ¯
    MODELS_INFO = {
        "RandomForest": ("models/best_randomforest_model.pkl", 0.8616),
        "XGBoost": ("models/best_xgboost_model.pkl", 0.8835),
        "LightGBM": ("models/best_lgbm_model.pkl", 0.8630)
    }

    # 1. åŠ è½½æ¨¡å‹
    print("=== åŠ è½½é›†æˆæ¨¡å‹ ===")
    models = {}
    r2_values = {}

    for name, (path, r2) in MODELS_INFO.items():
        try:
            model = joblib.load(path)
            models[name] = model
            r2_values[name] = r2
            print(f"âœ… {name}æ¨¡å‹åŠ è½½æˆåŠŸ! (æµ‹è¯•é›†RÂ²: {r2})")
        except Exception as e:
            print(f"âŒ {name}æ¨¡å‹åŠ è½½å¤±è´¥: {e}")

    if not models:
        print("âŒ æ²¡æœ‰æˆåŠŸåŠ è½½ä»»ä½•æ¨¡å‹")
        return None

    # è®¡ç®—æƒé‡
    total_r2 = sum(r2_values.values())
    weights = {name: r2 / total_r2 for name, r2 in r2_values.items()}

    print(f"\nğŸ“Š æ¨¡å‹æƒé‡åˆ†é… (åŸºäºæµ‹è¯•é›†RÂ²):")
    for name, weight in weights.items():
        print(f"   {name}: {weight:.4f} ({weight * 100:.2f}%)")

    # 2. åŠ è½½æ˜ å°„æ–‡ä»¶
    try:
        mapping_df = pd.read_csv('label_mappings/full_mapping_summary.csv')
        print("âœ… æ˜ å°„æ–‡ä»¶åŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"âŒ æ˜ å°„æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
        return None

    # 3. åŸºç¡€å®éªŒæ•°æ®ï¼ˆåŸºäºæ‚¨æä¾›çš„ä»£ç ï¼‰
    base_data = {
        'Structure': 'p-i-n',
        'HTL': 'NiOx',
        'HTL-2': 'Me-4PACz',
        'HTL_Passivator': '',
        'HTL-Addictive': 'DMPU',
        'ETL': 'C60',
        'ETL-2': 'SnO2',
        'ETL_Passivator': '',
        'ETL-Addictive': '',
        'Metal_Electrode': 'Cu',
        'Glass': 'FTO',
        'Perovskite': '(FA0.98MA0.02)0.95Cs0.05Pb(I0.98Br0.02)3',
        'Active_Area': 12.96,
        'Precursor_Solution': 'DMF:NMP (7:1)',
        'Precursor_Solution_Addictive': 'PbI2+MACI',
        'Deposition_Method': 'blade-coating',
        'Antisolvent': '',
        'Annealing_Temperature1': 120,
        'Annealing_Time1': 25,
        'Annealing_Temperature2': 0,
        'Annealing_Time2': 0,
        'P1Wavelength(nm)': 532,
        'P2Wavelength(nm)': 532,
        'P3Wavelength(nm)': 532,
        'total_scribing_line_width(Î¼m)': 235,
        'P1Width(Î¼m)': 40,
        'P2Width(Î¼m)': 65,
        'P3Width(Î¼m)': 40,
        'GFF': 95.36,
        'Type': 'Series',
        'submodule_number': 6,
        'P1Scan_Velocity(mm/s)': 4000,
        'P1etching_frequency(kHz)': 500,
        'P1Spot Size(Î¼m)': 40,
        'P1etching_Power(W)': 0,
        'P1etching_Power_percentage(%)': 40,
        'P2Scan_Velocity': 2000,
        'P2etching_frequency(kHz)': 500,
        'P2Spot Size(Î¼m)': 40,
        'P2etching_Power(W)': 0,
        'P2etching_Power_percentage(%)': 10,
        'P3Scan_Velocity': 2000,
        'P3etching_frequency(kHz)': 500,
        'P3Spot Size(Î¼m)': 40,
        'P3etching_Power(W)': 0,
        'P3etching_Power_percentage(%)': 9,
        'P1_P2Scribing_Spacing(Î¼m)': 45,
        'P2_P3Scribing_Spacing(Î¼m)': 45,
        'brand': '',
        'Cs': 0.05,
        'MA': 0.02,
        'FA': 0.93,
        'I': 0.98,  # è¿™æ˜¯æˆ‘ä»¬è¦æ›¿æ¢çš„åˆ—
        'Br': 0.02,  # è¿™æ˜¯æˆ‘ä»¬è¦æ›¿æ¢çš„åˆ—
        'Cl': 0.0,
        'Bandgap': 1.0  # åˆå§‹å€¼ï¼Œä¼šæ ¹æ®å®é™…è®¡ç®—æ›´æ–°
    }

    # 4. ç”ŸæˆIå’ŒBrçš„ç»„åˆ
    print("\nğŸ”¬ ç”ŸæˆIå’ŒBrç»„åˆ...")
    # Iå’ŒBrçš„æ¯”ä¾‹åº”è¯¥æ»¡è¶³ I + Br + Cl = 1ï¼Œè¿™é‡Œæˆ‘ä»¬å‡è®¾Clå›ºå®šä¸º0
    i_values = np.arange(0.5, 1.0, 0.05)  # Iä»0.5åˆ°0.95
    br_values = np.arange(0.05, 0.5, 0.05)  # Brä»0.05åˆ°0.45

    combinations = []
    for i_val in i_values:
        for br_val in br_values:
            if i_val + br_val <= 1.0:  # ç¡®ä¿I + Br <= 1
                cl_val = 1.0 - i_val - br_val  # Clçš„æ¯”ä¾‹
                if cl_val >= 0:  # ç¡®ä¿Clä¸ä¸ºè´Ÿ
                    combinations.append({
                        'I': round(i_val, 2),
                        'Br': round(br_val, 2),
                        'Cl': round(cl_val, 2)
                    })

    print(f"ç”Ÿæˆäº† {len(combinations)} ä¸ªIå’ŒBrç»„åˆ")

    # 5. å¯¹æ¯ä¸ªç»„åˆè¿›è¡Œé¢„æµ‹
    results = []
    print(f"\nğŸ¯ å¼€å§‹å¯¹ {len(combinations)} ä¸ªç»„åˆè¿›è¡Œé¢„æµ‹...")

    for i, combo in enumerate(combinations):
        # åˆ›å»ºæ–°æ ·æœ¬
        new_sample_data = base_data.copy()

        # æ›´æ–°Iå’ŒBrçš„å€¼
        new_sample_data['I'] = combo['I']
        new_sample_data['Br'] = combo['Br']
        new_sample_data['Cl'] = combo['Cl']

        # æ›´æ–°é’™é’›çŸ¿ç»„æˆ
        new_sample_data[
            'Perovskite'] = f'(FA{base_data["FA"]:.2f}MA{base_data["MA"]:.2f}){base_data["Cs"]:.2f}CsPb(I{combo["I"]:.2f}Br{combo["Br"]:.2f}Cl{combo["Cl"]:.2f})3'

        # åˆ›å»ºDataFrame
        new_sample = pd.DataFrame([new_sample_data])

        # è§£æé’™é’›çŸ¿ç»„æˆå¹¶æ·»åŠ å…ƒç´ æ¯”ä¾‹ - ä½¿ç”¨å¯¼å…¥çš„è§£æå‡½æ•°
        element_ratios = parse_perovskite_composition(new_sample_data['Perovskite'])

        for element in ['Cs', 'MA', 'FA', 'I', 'Br', 'Cl']:
            new_sample[element] = element_ratios.get(element, 0.0)

        # æ·»åŠ Bandgapç‰¹å¾
        element_cols = ['Cs', 'MA', 'FA', 'I', 'Br', 'Cl']
        new_sample['Bandgap'] = new_sample[element_cols].sum(axis=1)

        # ç§»é™¤Perovskiteåˆ—
        new_sample = new_sample.drop('Perovskite', axis=1)

        # ç¼–ç åˆ†ç±»ç‰¹å¾
        new_sample_encoded = encode_categorical_features(new_sample, mapping_df)

        # ç¡®ä¿æ‰€æœ‰åˆ—éƒ½æ˜¯æ•°å€¼ç±»å‹
        for col in new_sample_encoded.columns:
            if new_sample_encoded[col].dtype == 'object':
                try:
                    new_sample_encoded[col] = pd.to_numeric(new_sample_encoded[col])
                except:
                    new_sample_encoded[col] = 0

        # è°ƒæ•´ç‰¹å¾é¡ºåº
        if "XGBoost" in models and hasattr(models["XGBoost"], 'feature_names_'):
            expected_features = models["XGBoost"].feature_names_
            # æ·»åŠ ç¼ºå¤±ç‰¹å¾
            for feature in set(expected_features) - set(new_sample_encoded.columns):
                new_sample_encoded[feature] = 0
            # ç§»é™¤å¤šä½™ç‰¹å¾
            new_sample_encoded = new_sample_encoded[expected_features]

        # é›†æˆé¢„æµ‹
        predictions = {}
        for name, model in models.items():
            try:
                prediction = model.predict(new_sample_encoded)[0]
                predictions[name] = prediction
            except Exception as e:
                predictions[name] = 0

        # è®¡ç®—åŠ æƒå¹³å‡PCE
        if predictions:
            weighted_pce = sum(predictions[name] * weights[name] for name in predictions.keys())

            results.append({
                'I': combo['I'],
                'Br': combo['Br'],
                'Cl': combo['Cl'],
                'Cs': base_data['Cs'],
                'MA': base_data['MA'],
                'FA': base_data['FA'],
                'Bandgap': new_sample['Bandgap'].iloc[0],
                'Average_Predicted_PCE': weighted_pce,
                'RF_Prediction': predictions.get('RandomForest', 0),
                'XGB_Prediction': predictions.get('XGBoost', 0),
                'LGB_Prediction': predictions.get('LightGBM', 0)
            })

        # æ˜¾ç¤ºè¿›åº¦
        if (i + 1) % 10 == 0:
            print(f"   å·²å¤„ç† {i + 1}/{len(combinations)} ä¸ªç»„åˆ...")

    # 6. åˆ†æç»“æœ
    if results:
        results_df = pd.DataFrame(results).sort_values('Average_Predicted_PCE', ascending=False)

        print(f"\nâœ… é¢„æµ‹å®Œæˆ! å…±ç”Ÿæˆ {len(results_df)} ä¸ªæœ‰æ•ˆé¢„æµ‹ç»“æœ")

        # æ˜¾ç¤ºå‰10ä¸ªæœ€ä½³ç»“æœ
        print("\nğŸ† é¢„æµ‹ç»“æœæ’åå‰10çš„Iå’ŒBrç»„åˆ:")
        print("=" * 100)
        for i, row in results_df.head(10).iterrows():
            print(f"{i + 1:2d}. I: {row['I']:.2f}, Br: {row['Br']:.2f}, Cl: {row['Cl']:.2f}, "
                  f"Cs: {row['Cs']:.2f}, MA: {row['MA']:.2f}, FA: {row['FA']:.2f}, "
                  f"Bandgap: {row['Bandgap']:.3f}, Predicted_PCE: {row['Average_Predicted_PCE']:.2f}%")

        # ç»Ÿè®¡ä¿¡æ¯
        print(f"\nğŸ“Š é¢„æµ‹ç»“æœç»Ÿè®¡:")
        print(f"   æœ€é«˜PCE: {results_df['Average_Predicted_PCE'].max():.2f}%")
        print(f"   æœ€ä½PCE: {results_df['Average_Predicted_PCE'].min():.2f}%")
        print(f"   å¹³å‡PCE: {results_df['Average_Predicted_PCE'].mean():.2f}%")
        print(f"   ä¸­ä½æ•°PCE: {results_df['Average_Predicted_PCE'].median():.2f}%")

        # æœ€ä½³ç»„åˆ
        best_combo = results_df.iloc[0]
        print(f"\nâ­ æœ€ä½³ç»„åˆæ¨è:")
        print(f"   I: {best_combo['I']:.2f}, Br: {best_combo['Br']:.2f}, Cl: {best_combo['Cl']:.2f}")
        print(f"   å¯¹åº”çš„Cs: {best_combo['Cs']:.2f}, MA: {best_combo['MA']:.2f}, FA: {best_combo['FA']:.2f}")
        print(f"   Bandgap: {best_combo['Bandgap']:.3f}")
        print(f"   é¢„æµ‹PCE: {best_combo['Average_Predicted_PCE']:.2f}%")

        # ä¿å­˜ç»“æœ
        results_df.to_csv('pce_Predict/i_br_combinations_predictions.csv', index=False)
        print(f"\nğŸ’¾ å®Œæ•´é¢„æµ‹ç»“æœå·²ä¿å­˜åˆ° pce_Predict/i_br_combinations_predictions.csv")

        # ä¿å­˜å‰20ä¸ªæœ€ä½³ç»“æœ
        results_df.head(20).to_csv('pce_Predict/i_br_best_combinations.csv', index=False)
        print(f"ğŸ’¾ å‰20ä¸ªæœ€ä½³ç»“æœå·²ä¿å­˜åˆ° pce_Predict/i_br_best_combinations.csv")

        return results_df
    else:
        print("âŒ æ²¡æœ‰ç”Ÿæˆæœ‰æ•ˆçš„é¢„æµ‹ç»“æœ")
        return None


if __name__ == "__main__":
    print("=== é’™é’›çŸ¿å¤ªé˜³èƒ½ç”µæ± I-Brç»„åˆPCEé¢„æµ‹ç³»ç»Ÿ ===\n")
    results = predict_i_br_combinations()