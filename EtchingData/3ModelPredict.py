import pickle
import pandas as pd
import numpy as np
import re
from collections import defaultdict
import warnings
import joblib
from sklearn.ensemble import RandomForestRegressor
import xgboost as xgb
import lightgbm as lgb

warnings.filterwarnings('ignore')


def prepare_sample_data(sample_data, mapping_df, historical_data, fixed_bandgap=1.6095):
    """
    å‡†å¤‡æ ·æœ¬æ•°æ®å¹¶è¿›è¡Œé¢„å¤„ç†

    Parameters:
    - sample_data: æ ·æœ¬æ•°æ®å­—å…¸
    - mapping_df: æ˜ å°„æ•°æ®æ¡†
    - historical_data: å†å²æ•°æ®
    - fixed_bandgap: å›ºå®šçš„Bandgapå€¼
    """
    # ä½¿ç”¨å›ºå®šçš„Bandgapå€¼
    sample_data['Bandgap'] = fixed_bandgap
    print(f"âœ… ä½¿ç”¨å›ºå®šBandgap: {sample_data['Bandgap']:.4f} eV")

    # åˆ›å»ºæ–°æ•°æ®çš„DataFrame
    new_sample = pd.DataFrame([sample_data])

    # ç§»é™¤Perovskiteåˆ—ï¼ˆå› ä¸ºå·²ç»æœ‰å…ƒç´ æ¯”ä¾‹å’ŒBandgapï¼‰
    if 'Perovskite' in new_sample.columns:
        new_sample = new_sample.drop('Perovskite', axis=1)
        print("âœ… å·²ç§»é™¤Perovskiteåˆ—ï¼Œä¿ç•™å…ƒç´ æ¯”ä¾‹å’ŒBandgapç‰¹å¾")

    # åº”ç”¨æ•°å€¼æ˜ å°„
    categorical_features = [
        'Structure', 'HTL', 'HTL-2', 'HTL_Passivator', 'HTL-Addictive',
        'ETL', 'ETL-2', 'ETL_Passivator', 'ETL-Addictive',
        'Metal_Electrode', 'Glass', 'Precursor_Solution',
        'Precursor_Solution_Addictive', 'Deposition_Method',
        'Antisolvent', 'Type', 'brand'
    ]

    print("\nğŸ”§ å¼€å§‹ç‰¹å¾ç¼–ç ...")

    for feature in categorical_features:
        if feature in new_sample.columns:
            # è·å–è¯¥ç‰¹å¾çš„æ˜ å°„å…³ç³»
            feature_mapping = mapping_df[mapping_df['Feature'] == feature]

            if len(feature_mapping) > 0:
                # åˆ›å»ºæ˜ å°„å­—å…¸
                mapping_dict = dict(zip(feature_mapping['Original'], feature_mapping['Encoded']))

                # åº”ç”¨æ˜ å°„
                original_value = new_sample[feature].iloc[0]

                # å¤„ç†ç©ºå€¼
                if original_value == '' or pd.isna(original_value):
                    # æŸ¥æ‰¾ç©ºå€¼çš„æ˜ å°„
                    empty_mapping = feature_mapping[feature_mapping['Original'].isna()]
                    if len(empty_mapping) > 0:
                        encoded_value = empty_mapping['Encoded'].iloc[0]
                    else:
                        # å¦‚æœæ²¡æœ‰ç©ºå€¼æ˜ å°„ï¼Œä½¿ç”¨0
                        encoded_value = 0
                else:
                    # æ­£å¸¸æ˜ å°„
                    encoded_value = mapping_dict.get(original_value, 0)

                new_sample[feature] = encoded_value
                print(f"   {feature}: '{original_value}' -> {encoded_value}")
            else:
                print(f"   âš ï¸  ç‰¹å¾ '{feature}' åœ¨æ˜ å°„æ–‡ä»¶ä¸­æœªæ‰¾åˆ°ï¼Œä½¿ç”¨é»˜è®¤å€¼0")
                new_sample[feature] = 0

    # ç¡®ä¿æ‰€æœ‰åˆ—éƒ½æ˜¯æ•°å€¼ç±»å‹
    for col in new_sample.columns:
        if new_sample[col].dtype == 'object':
            try:
                new_sample[col] = pd.to_numeric(new_sample[col])
            except:
                print(f"   âš ï¸  æ— æ³•å°†åˆ— '{col}' è½¬æ¢ä¸ºæ•°å€¼ç±»å‹ï¼Œä½¿ç”¨0")
                new_sample[col] = 0

    # ç¡®ä¿ç‰¹å¾é¡ºåºä¸è®­ç»ƒæ—¶ä¸€è‡´
    try:
        # è·å–å†å²æ•°æ®çš„ç‰¹å¾é¡ºåºï¼ˆæ’é™¤ç›®æ ‡å˜é‡PCEï¼‰
        expected_features = [col for col in historical_data.columns if col != 'PCE']

        print(f"\nğŸ“‹ æœŸæœ›çš„ç‰¹å¾æ•°é‡: {len(expected_features)}")

        # æ£€æŸ¥ç¼ºå¤±å’Œå¤šä½™çš„ç‰¹å¾
        missing_features = set(expected_features) - set(new_sample.columns)
        extra_features = set(new_sample.columns) - set(expected_features)

        print(f"ğŸ” ç‰¹å¾åŒ¹é…æ£€æŸ¥:")
        print(f"   ç¼ºå¤±ç‰¹å¾: {missing_features}")
        print(f"   å¤šä½™ç‰¹å¾: {extra_features}")

        # æ·»åŠ ç¼ºå¤±ç‰¹å¾
        for feature in missing_features:
            print(f"   â• æ·»åŠ ç¼ºå¤±ç‰¹å¾: {feature} = 0")
            new_sample[feature] = 0

        # ç§»é™¤å¤šä½™ç‰¹å¾
        if extra_features:
            print(f"   â– ç§»é™¤å¤šä½™ç‰¹å¾: {extra_features}")
            new_sample = new_sample.drop(columns=list(extra_features))

        # é‡æ–°æ’åˆ—åˆ—é¡ºåº
        new_sample = new_sample[expected_features]
        print(f"   âœ… ç‰¹å¾é¡ºåºå·²è°ƒæ•´ï¼Œå½“å‰ç‰¹å¾æ•°é‡: {len(new_sample.columns)}")

    except Exception as e:
        print(f"âš ï¸  ç‰¹å¾é¡ºåºè°ƒæ•´å¤±è´¥: {e}")

    return new_sample


def predict_pce_for_first_sample():
    """
    ä½¿ç”¨ä¸‰ä¸ªä¸åŒçš„æ¨¡å‹åˆ†åˆ«é¢„æµ‹ç¬¬ä¸€ç»„åŸå§‹æ•°æ®çš„PCE
    """
    # 1. åŠ è½½ä¸‰ä¸ªPCEé¢„æµ‹æ¨¡å‹
    models = {}
    try:
        # åŠ è½½éšæœºæ£®æ—æ¨¡å‹
        rf_model = joblib.load('models/best_randomforest_model.pkl')
        models['Random Forest'] = rf_model
        print("âœ… éšæœºæ£®æ—æ¨¡å‹åŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"âŒ éšæœºæ£®æ—æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return None

    try:
        # åŠ è½½LightGBMæ¨¡å‹
        lgb_model = joblib.load('models/best_lgbm_model.pkl')
        models['LightGBM'] = lgb_model
        print("âœ… LightGBMæ¨¡å‹åŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"âŒ LightGBMæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return None

    try:
        # åŠ è½½XGBoostæ¨¡å‹
        xgb_model = joblib.load('models/best_xgboost_model.pkl')
        models['XGBoost'] = xgb_model
        print("âœ… XGBoostæ¨¡å‹åŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"âŒ XGBoostæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return None

    print(f"ğŸ“‹ åŠ è½½äº† {len(models)} ä¸ªæ¨¡å‹")

    # 2. åŠ è½½å†å²æ•°æ®ä»¥è·å–ç‰¹å¾ç»“æ„
    try:
        historical_data = pd.read_excel('FinalData.xlsx')
        print("âœ… å†å²æ•°æ®åŠ è½½æˆåŠŸ")
        print(f"å†å²æ•°æ®ç‰¹å¾æ•°é‡: {len(historical_data.columns)}")
    except Exception as e:
        print(f"âŒ å†å²æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return None

    # 3. åŠ è½½æ˜ å°„æ–‡ä»¶
    try:
        mapping_df = pd.read_csv('label_mappings/full_mapping_summary.csv')
        print("âœ… æ˜ å°„æ–‡ä»¶åŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"âŒ æ˜ å°„æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
        return None

    # 4. å‡†å¤‡ç¬¬ä¸€ç»„æ•°æ®ï¼ˆåŸå§‹æ•°æ®ï¼‰
    sample1_data = {
        'Structure': 'p-i-n',
        'HTL': 'NiOx',
        'HTL-2': 'Me-4PACz',
        'HTL_Passivator': '',
        'HTL-Addictive': 'DMPU',
        'ETL': 'C60',
        'ETL-2': 'SnO2',
        'ETL_Passivator': '',
        'ETL-Addictive': '',
        'Metal_Electrode': 'Cu',
        'Glass': 'FTO',
        'Perovskite': '(FA0.98MA0.02)0.95Cs0.05Pb(l0.98Br0.02)3',
        'Active_Area': 12.96,
        'Precursor_Solution': 'DMF:NMP (7:1)',
        'Precursor_Solution_Addictive': '',
        'Deposition_Method': 'blade-coating',
        'Antisolvent': '',
        'Annealing_Temperature1': 120,
        'Annealing_Time1': 25,
        'Annealing_Temperature2': 0,
        'Annealing_Time2': 0,
        'P1Wavelength(nm)': 532,
        'P2Wavelength(nm)': 532,
        'P3Wavelength(nm)': 532,
        'total_scribing_line_width(Î¼m)': 235,
        'P1Width(Î¼m)': 40,
        'P2Width(Î¼m)': 65,
        'P3Width(Î¼m)': 40,
        'GFF': 95.36,
        'Type': 'Series',
        'submodule_number': 6,
        'P1Scan_Velocity(mm/s)': 4000,
        'P1etching_frequency(kHz)': 500,
        'P1Spot Size(Î¼m)': 40,
        'P1etching_Power(W)': 0,
        'P1etching_Power_percentage(%)': 40,
        'P2Scan_Velocity': 2000,
        'P2etching_frequency(kHz)': 500,
        'P2Spot Size(Î¼m)': 40,
        'P2etching_Power(W)': 0,
        'P2etching_Power_percentage(%)': 10,
        'P3Scan_Velocity': 2000,
        'P3etching_frequency(kHz)': 500,
        'P3Spot Size(Î¼m)': 40,
        'P3etching_Power(W)': 0,
        'P3etching_Power_percentage(%)': 9,
        'P1_P2Scribing_Spacing(Î¼m)': 45,
        'P2_P3Scribing_Spacing(Î¼m)': 45,
        'brand': '',
        'Cs': 0.05,
        'MA': 0.02,
        'FA': 0.93,
        'I': 2.94,
        'Br': 0.96,
        'Pb': 1.0,
        'Cl': 0,
        'Bandgap': 1.6095  # å›ºå®šBandgapå€¼
    }

    # å­˜å‚¨æ‰€æœ‰é¢„æµ‹ç»“æœ
    all_predictions = {}

    print("=" * 60)
    print("ğŸ¯ ç¬¬ä¸€ç»„æ•°æ®é¢„æµ‹ (åŸå§‹é…ç½®)")
    print("=" * 60)
    print("é…ç½®: HTL = NiOx, HTL-2 = Me-4PACz, HTL-Addictive = DMPU, ETL_Passivator = ç©ºå€¼")
    print(f"ä½¿ç”¨å›ºå®šBandgapå€¼: 1.6095 eV")

    # å‡†å¤‡ç¬¬ä¸€ç»„æ•°æ®
    sample1_processed = prepare_sample_data(sample1_data, mapping_df, historical_data, fixed_bandgap=1.6095)

    # åˆ†åˆ«ç”¨ä¸‰ä¸ªæ¨¡å‹è¿›è¡Œé¢„æµ‹
    for model_name, model in models.items():
        try:
            pce_prediction = model.predict(sample1_processed)[0]
            all_predictions[model_name] = pce_prediction
            print(f"\nğŸ“Š {model_name} é¢„æµ‹ç»“æœ:")
            print(f"   é¢„æµ‹PCE: {pce_prediction:.2f} %")

            # æä¾›æ€§èƒ½è¯„ä¼°
            if pce_prediction > 20:
                print("   â­ ä¼˜ç§€æ€§èƒ½!")
            elif pce_prediction > 18:
                print("   ğŸ‘ è‰¯å¥½æ€§èƒ½!")
            else:
                print("   ğŸ’¡ å»ºè®®è¿›ä¸€æ­¥ä¼˜åŒ–å·¥è‰ºå‚æ•°!")
        except Exception as e:
            print(f"\nâŒ {model_name} é¢„æµ‹å¤±è´¥: {e}")
            all_predictions[model_name] = None

    return all_predictions


# ä¸»å‡½æ•°
if __name__ == "__main__":
    print("=== é’™é’›çŸ¿å¤ªé˜³èƒ½ç”µæ± PCEé¢„æµ‹ç³»ç»Ÿ ===")
    print("ä½¿ç”¨ä¸‰ä¸ªæ¨¡å‹åˆ†åˆ«é¢„æµ‹ç¬¬ä¸€ç»„åŸå§‹æ•°æ®")
    print("é…ç½®: HTL = NiOx, HTL-2 = Me-4PACz, HTL-Addictive = DMPU, ETL_Passivator = ç©ºå€¼")
    print("ä½¿ç”¨å›ºå®šBandgapå€¼: 1.6095 eV")
    print("é¢„æµ‹æ¨¡å‹: Random Forest, LightGBM, XGBoost")
    print("=" * 60)

    # é¢„æµ‹ç¬¬ä¸€ç»„æ•°æ®çš„PCE
    predictions = predict_pce_for_first_sample()

    if predictions:
        print("\n" + "=" * 60)
        print("ğŸ“Š æ‰€æœ‰æ¨¡å‹é¢„æµ‹ç»“æœæ±‡æ€»")
        print("=" * 60)

        for model_name, pce in predictions.items():
            if pce is not None:
                print(f"{model_name}: {pce:.2f} %")
            else:
                print(f"{model_name}: é¢„æµ‹å¤±è´¥")

        print("\n" + "=" * 60)
        print("ğŸ“ˆ é¢„æµ‹ç»“æœç»Ÿè®¡")
        print("=" * 60)

        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        valid_predictions = [p for p in predictions.values() if p is not None]
        if valid_predictions:
            print(f"é¢„æµ‹æ¨¡å‹æ•°é‡: {len(valid_predictions)}")
            print(f"å¹³å‡é¢„æµ‹PCE: {np.mean(valid_predictions):.2f} %")
            print(f"æœ€é«˜é¢„æµ‹PCE: {max(valid_predictions):.2f} %")
            print(f"æœ€ä½é¢„æµ‹PCE: {min(valid_predictions):.2f} %")
            print(f"é¢„æµ‹PCEèŒƒå›´: {max(valid_predictions) - min(valid_predictions):.2f} %")
        else:
            print("æ‰€æœ‰æ¨¡å‹é¢„æµ‹éƒ½å¤±è´¥äº†")
    else:
        print("é¢„æµ‹å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ¨¡å‹å’Œæ•°æ®")