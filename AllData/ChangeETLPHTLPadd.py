import pandas as pd
import numpy as np
import warnings
import pickle
import joblib
import os
from catboost import CatBoostRegressor
from datetime import datetime

warnings.filterwarnings('ignore')


class BestNIPOptimizer:
    def __init__(self, data_path="FinalDataAll.xlsx", bestnip_path="bestnip.xlsx"):
        self.data_path = data_path
        self.bestnip_path = bestnip_path

        # è¦ä¼˜åŒ–çš„ç‰¹å¾
        self.target_features = [
            'ETL_Passivator',
            'HTL_Passivator',
            'Precursor_Solution_Addictive'
        ]

        # æ¨¡å‹æƒé‡é…ç½®ï¼ˆåŸºäºæµ‹è¯•é›†RÂ²ï¼‰
        self.model_configs = {
            'rf': {'path': 'models/best_rf_model.pkl', 'r2': 0.6892},
            'xgb': {'path': 'models/best_xgb_model.pkl', 'r2': 0.7630},
            'catboost': {'path': 'models/best_catboost_model.pkl', 'r2': 0.6762},
            'lgbm': {'path': 'models/best_lgbm_model.pkl', 'r2': 0.7446}
        }

        # åŠ è½½æ•°æ®
        self.df = None
        self.bestnip_records = None
        self.models = {}
        self.weights = {}
        self.mapping_df = None
        self.model_features = {}  # å­˜å‚¨æ¯ä¸ªæ¨¡å‹çš„ç‰¹å¾åˆ—è¡¨

        # ç»“æœå­˜å‚¨
        self.optimization_results = {}

        # åˆ›å»ºç»“æœç›®å½•
        self.results_dir = 'bestnip_simple_optimization'
        os.makedirs(self.results_dir, exist_ok=True)
        self.timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        # åŠ è½½æ•°æ®
        self.load_data()

    def load_data(self):
        """åŠ è½½æ‰€æœ‰å¿…è¦çš„æ•°æ®"""
        print("ğŸ“‚ åŠ è½½æ•°æ®...")

        # åŠ è½½bestnip.xlsxä¸­çš„è®°å½•
        try:
            self.bestnip_records = pd.read_excel(self.bestnip_path)
            print(f"âœ… BestNIPè®°å½•åŠ è½½æˆåŠŸ: {len(self.bestnip_records)} æ¡")

            # æ˜¾ç¤ºå‰å‡ æ¡è®°å½•ä¿¡æ¯
            print(f"\nğŸ“‹ BestNIPè®°å½•å‰{min(3, len(self.bestnip_records))}æ¡è¯¦ç»†ä¿¡æ¯:")
            for idx, row in self.bestnip_records.head(3).iterrows():
                print(f"è®°å½• {idx + 1}:")
                print(f"  Record ID: {row.get('Record', 'N/A')}")
                print(f"  PCE: {row.get('PCE', 'N/A'):.2f}%")
                print(f"  Active_Area: {row.get('Active_Area', 'N/A'):.2f} cmÂ²")
                if 'Structure' in row:
                    print(f"  Structure: {row.get('Structure', 'N/A')}")
                print(f"  ETL_Passivator: {row.get('ETL_Passivator', 'N/A')}")
                print(f"  HTL_Passivator: {row.get('HTL_Passivator', 'N/A')}")
                print(f"  Precursor_Solution_Addictive: {row.get('Precursor_Solution_Addictive', 'N/A')}")
                print("-" * 40)

        except Exception as e:
            print(f"âŒ åŠ è½½BestNIPè®°å½•å¤±è´¥: {e}")
            raise

        # åŠ è½½æ•°æ®åº“ç”¨äºè·å–å¯èƒ½çš„å–å€¼
        try:
            self.df = pd.read_excel(self.data_path)
            print(f"âœ… æ•°æ®åº“åŠ è½½æˆåŠŸ: {len(self.df)} æ¡è®°å½•")

            # æ£€æŸ¥ç›®æ ‡ç‰¹å¾æ˜¯å¦åœ¨æ•°æ®åº“ä¸­
            for feature in self.target_features:
                if feature in self.df.columns:
                    print(f"âœ… æ•°æ®åº“ä¸­åŒ…å«ç‰¹å¾: {feature}")
                else:
                    print(f"âš ï¸ æ•°æ®åº“ä¸­ä¸åŒ…å«ç‰¹å¾: {feature}")

        except Exception as e:
            print(f"âŒ åŠ è½½æ•°æ®åº“å¤±è´¥: {e}")
            print(f"è¯·æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨: {self.data_path}")
            raise

        # åŠ è½½é›†æˆæ¨¡å‹
        self.load_ensemble_models()

        # å°è¯•åŠ è½½æ˜ å°„æ–‡ä»¶ï¼ˆä»…ç”¨äºæ˜¾ç¤ºï¼Œä¸ç”¨äºç¼–ç ï¼‰
        self.load_mapping_file()

    def load_ensemble_models(self):
        """åŠ è½½é›†æˆæ¨¡å‹"""
        print("\nğŸ¤– åŠ è½½é›†æˆæ¨¡å‹...")

        # è®¡ç®—æ€»RÂ²ç”¨äºæƒé‡å½’ä¸€åŒ–
        total_r2 = sum(config['r2'] for config in self.model_configs.values())

        # å°è¯•ä¸åŒçš„CatBoostæ¨¡å‹è·¯å¾„
        catboost_paths = [
            'models/best_catboost_model.pkl',
            'models/best_catboost_model.cbm'
        ]

        successful_models = 0

        for model_name, config in self.model_configs.items():
            try:
                if model_name == 'catboost':
                    # å°è¯•å¤šä¸ªå¯èƒ½çš„CatBoostæ¨¡å‹è·¯å¾„
                    catboost_loaded = False
                    for path in catboost_paths:
                        try:
                            if path.endswith('.cbm'):
                                model = CatBoostRegressor()
                                model.load_model(path)
                            else:
                                model = joblib.load(path)
                            catboost_loaded = True
                            print(f"âœ… CatBoostæ¨¡å‹ä» {path} åŠ è½½æˆåŠŸ")
                            break
                        except Exception as e:
                            continue

                    if not catboost_loaded:
                        raise Exception("æ‰€æœ‰CatBoostæ¨¡å‹è·¯å¾„éƒ½å¤±è´¥")
                else:
                    model = joblib.load(config['path'])

                self.models[model_name] = model
                self.weights[model_name] = config['r2'] / total_r2
                successful_models += 1
                print(f"âœ… {model_name.upper()}æ¨¡å‹åŠ è½½æˆåŠŸ, æƒé‡: {self.weights[model_name]:.4f}")

                # è®°å½•æ¨¡å‹çš„ç‰¹å¾
                if hasattr(model, 'feature_names_'):
                    self.model_features[model_name] = model.feature_names_
                    print(f"  ğŸ“‹ ç‰¹å¾æ•°é‡: {len(model.feature_names_)}")
                else:
                    # å¦‚æœæ²¡æœ‰feature_names_å±æ€§ï¼Œä½¿ç”¨è®­ç»ƒæ•°æ®çš„ç‰¹å¾
                    if self.df is not None:
                        # æ’é™¤ç›®æ ‡å˜é‡PCE
                        features = [col for col in self.df.columns if col != 'PCE']
                        self.model_features[model_name] = features
                        print(f"  ğŸ“‹ ä½¿ç”¨æ•°æ®åº“ç‰¹å¾: {len(features)} ä¸ª")

            except Exception as e:
                print(f"âŒ {model_name.upper()}æ¨¡å‹åŠ è½½å¤±è´¥: {e}")

        # å¦‚æœæ²¡æœ‰æ¨¡å‹æˆåŠŸåŠ è½½ï¼Œé€€å‡º
        if successful_models == 0:
            print("âŒ æ‰€æœ‰æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œæ— æ³•è¿›è¡Œåˆ†æ")
            exit(1)

        print("\næ¨¡å‹æƒé‡æ±‡æ€»:")
        for model_name, weight in self.weights.items():
            if model_name in self.models:
                print(f"  {model_name.upper()}: {weight:.4f}")

        # å¦‚æœCatBooståŠ è½½å¤±è´¥ï¼Œé‡æ–°è®¡ç®—æƒé‡
        if 'catboost' not in self.models:
            print("\nâš ï¸ CatBoostæ¨¡å‹åŠ è½½å¤±è´¥ï¼Œé‡æ–°è®¡ç®—å…¶ä»–æ¨¡å‹çš„æƒé‡...")
            remaining_r2 = sum(config['r2'] for model_name, config in self.model_configs.items()
                               if model_name in self.models)
            for model_name in self.models:
                self.weights[model_name] = self.model_configs[model_name]['r2'] / remaining_r2

            print("è°ƒæ•´åçš„æ¨¡å‹æƒé‡:")
            for model_name, weight in self.weights.items():
                if model_name in self.models:
                    print(f"  {model_name.upper()}: {weight:.4f}")

    def load_mapping_file(self):
        """å°è¯•åŠ è½½æ˜ å°„æ–‡ä»¶ï¼ˆä»…ç”¨äºæ˜¾ç¤ºï¼Œä¸ç”¨äºç¼–ç ï¼‰"""
        mapping_paths = [
            'label_mappings/full_mapping_summary.csv',
            '../label_mappings/full_mapping_summary.csv',
            './label_mappings/full_mapping_summary.csv'
        ]

        for path in mapping_paths:
            if os.path.exists(path):
                try:
                    self.mapping_df = pd.read_csv(path)
                    print(f"âœ… æ˜ å°„æ–‡ä»¶åŠ è½½æˆåŠŸ: {path}ï¼ˆä»…ç”¨äºæ˜¾ç¤ºï¼‰")
                    return
                except Exception as e:
                    print(f"âŒ åŠ è½½æ˜ å°„æ–‡ä»¶å¤±è´¥ {path}: {e}")

        print("âš ï¸ æœªæ‰¾åˆ°æ˜ å°„æ–‡ä»¶")

    def get_unique_feature_values(self, feature_name):
        """ä»æ•°æ®åº“ä¸­è·å–ç‰¹å¾çš„å”¯ä¸€å€¼"""
        if self.df is None or feature_name not in self.df.columns:
            print(f"âš ï¸ æ•°æ®åº“ä¸­ä¸å­˜åœ¨ç‰¹å¾: {feature_name}")
            return []

        try:
            # è·å–æ‰€æœ‰éç©ºå”¯ä¸€å€¼
            unique_values = self.df[feature_name].dropna().unique()

            # è½¬æ¢ä¸ºåˆ—è¡¨å¹¶æ’åº
            values_list = sorted(list(unique_values))

            # é™åˆ¶æ•°é‡ï¼Œé¿å…è¿‡å¤š
            if len(values_list) > 50:
                print(f"âš ï¸ ç‰¹å¾ {feature_name} æœ‰ {len(values_list)} ä¸ªå€¼ï¼Œå–å‰50ä¸ª")
                values_list = values_list[:50]

            print(f"ğŸ“Š ç‰¹å¾ {feature_name} æœ‰ {len(values_list)} ä¸ªå¯èƒ½å–å€¼")
            return values_list

        except Exception as e:
            print(f"âŒ è·å–ç‰¹å¾ {feature_name} çš„å”¯ä¸€å€¼å¤±è´¥: {e}")
            return []

    def prepare_input_data(self, base_record, feature_name, feature_value):
        """å‡†å¤‡è¾“å…¥æ•°æ®ç”¨äºé¢„æµ‹"""
        # åˆ›å»ºä¸€ä¸ªç©ºçš„DataFrameï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªæ¨¡å‹çš„ç‰¹å¾ä½œä¸ºå‚è€ƒ
        if not self.models:
            print("âŒ æ²¡æœ‰å¯ç”¨çš„æ¨¡å‹")
            return pd.DataFrame()

        # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ¨¡å‹çš„ç‰¹å¾åˆ—è¡¨
        model_name = list(self.models.keys())[0]
        feature_columns = self.model_features.get(model_name, [])

        if not feature_columns:
            print(f"âš ï¸ æ— æ³•è·å–æ¨¡å‹ {model_name} çš„ç‰¹å¾åˆ—è¡¨")
            return pd.DataFrame()

        # åˆ›å»ºä¸€ä¸ªç©ºçš„DataFrameï¼ŒåŒ…å«æ‰€æœ‰ç‰¹å¾
        input_data = pd.DataFrame(columns=feature_columns)

        # åˆå§‹åŒ–æ‰€æœ‰ç‰¹å¾å€¼ä¸º0
        for col in feature_columns:
            input_data.loc[0, col] = 0

        # ä»base_recordå¤åˆ¶ç‰¹å¾å€¼
        for col in base_record.index:
            if col in feature_columns:
                try:
                    input_data.loc[0, col] = float(base_record[col])
                except:
                    input_data.loc[0, col] = 0

        # è®¾ç½®ç›®æ ‡ç‰¹å¾çš„æ–°å€¼
        if feature_name in feature_columns:
            try:
                input_data.loc[0, feature_name] = float(feature_value)
            except:
                input_data.loc[0, feature_name] = 0
        else:
            print(f"âš ï¸ ç‰¹å¾ {feature_name} ä¸åœ¨æ¨¡å‹ç‰¹å¾åˆ—è¡¨ä¸­")

        # ç¡®ä¿æ‰€æœ‰åˆ—éƒ½æ˜¯æ•°å€¼ç±»å‹
        for col in feature_columns:
            input_data[col] = pd.to_numeric(input_data[col], errors='coerce').fillna(0)

        return input_data

    def align_features(self, data_df, model_name):
        """ç¡®ä¿ç‰¹å¾ä¸æ¨¡å‹æœŸæœ›çš„ç‰¹å¾å¯¹é½"""
        if model_name not in self.model_features:
            print(f"âš ï¸ æ¨¡å‹ {model_name} æ²¡æœ‰ç‰¹å¾åˆ—è¡¨")
            return data_df

        expected_features = self.model_features[model_name]

        # æ£€æŸ¥æ•°æ®æ˜¯å¦åŒ…å«æ‰€æœ‰æœŸæœ›çš„ç‰¹å¾
        missing_features = set(expected_features) - set(data_df.columns)
        extra_features = set(data_df.columns) - set(expected_features)

        if missing_features:
            print(f"âš ï¸ æ•°æ®ç¼ºå¤± {len(missing_features)} ä¸ªç‰¹å¾ï¼Œå°†ç”¨0å¡«å……")
            for feature in missing_features:
                data_df[feature] = 0

        if extra_features:
            print(f"âš ï¸ æ•°æ®æœ‰ {len(extra_features)} ä¸ªé¢å¤–ç‰¹å¾ï¼Œå°†è¢«ç§»é™¤")
            data_df = data_df.drop(columns=list(extra_features))

        # ç¡®ä¿ç‰¹å¾é¡ºåºä¸€è‡´
        data_df = data_df[expected_features]

        return data_df

    def predict_pce_ensemble(self, record_data):
        """ä½¿ç”¨é›†æˆæ¨¡å‹é¢„æµ‹PCEå€¼ï¼ˆåŠ æƒå¹³å‡ï¼‰"""
        try:
            predictions = []
            weights_used = []

            for model_name, model in self.models.items():
                # å¯¹é½ç‰¹å¾
                aligned_data = self.align_features(record_data.copy(), model_name)

                # é¢„æµ‹PCE
                predicted_pce = model.predict(aligned_data)[0]

                # åº”ç”¨æƒé‡
                weight = self.weights[model_name]
                predictions.append(predicted_pce * weight)
                weights_used.append(weight)

            # è®¡ç®—åŠ æƒå¹³å‡
            if weights_used:
                ensemble_prediction = sum(predictions) / sum(weights_used)
                return round(ensemble_prediction, 4)
            else:
                return 0.0

        except Exception as e:
            print(f"âŒ é›†æˆæ¨¡å‹é¢„æµ‹å¤±è´¥: {e}")
            # è¿”å›åŸºäºç®€å•è§„åˆ™çš„é¢„æµ‹å€¼
            base_pce = 18.0 + np.random.rand() * 2
            return round(base_pce, 4)

    def find_alternative_values(self, record_idx, record, feature_name, num_alternatives=3):
        """ä¸ºå•æ¡è®°å½•çš„å•ä¸ªç‰¹å¾å¯»æ‰¾æœ€ä½³æ›¿ä»£å€¼"""
        record_id = record.get('Record', f'Record_{record_idx + 1}')
        original_value = record.get(feature_name, '')
        original_pce = record.get('PCE', 0)

        print(f"\nğŸ” å¯»æ‰¾è®°å½•{record_idx + 1}çš„ç‰¹å¾ {feature_name} çš„æ›¿ä»£å€¼")
        print(f"  åŸå§‹å€¼: '{original_value}', åŸå§‹PCE: {original_pce:.2f}%")

        # è·å–æ‰€æœ‰å¯èƒ½å–å€¼
        possible_values = self.get_unique_feature_values(feature_name)

        if not possible_values:
            print(f"  âš ï¸ æ²¡æœ‰æ‰¾åˆ°å¯èƒ½çš„å–å€¼")
            return []

        # æµ‹è¯•æ¯ä¸ªå–å€¼ï¼Œæ’é™¤ä¸åŸå€¼ç›¸åŒçš„å–å€¼
        tested_values = []
        total_tests = len(possible_values)
        print(f"  å°†æµ‹è¯• {total_tests} ä¸ªå¯èƒ½å–å€¼ï¼ˆæ’é™¤åŸå€¼ï¼‰...")

        for i, value in enumerate(possible_values):
            # è·³è¿‡ä¸åŸå€¼ç›¸åŒçš„å–å€¼
            if str(value) == str(original_value):
                continue

            # å‡†å¤‡æ•°æ®
            input_data = self.prepare_input_data(record, feature_name, value)

            if input_data.empty:
                continue

            # ä½¿ç”¨é›†æˆæ¨¡å‹é¢„æµ‹PCE
            predicted_pce = self.predict_pce_ensemble(input_data)

            tested_values.append({
                'value': value,
                'pce': predicted_pce,
                'improvement': predicted_pce - original_pce
            })

            # æ˜¾ç¤ºè¿›åº¦
            if (i + 1) % 10 == 0 or (i + 1) == total_tests:
                progress = (i + 1) / total_tests * 100
                print(f"  è¿›åº¦: {i + 1}/{total_tests} ({progress:.1f}%)...")

        if not tested_values:
            print(f"  âš ï¸ æ²¡æœ‰æ‰¾åˆ°æ›¿ä»£å€¼ï¼ˆæ‰€æœ‰å€¼éƒ½ä¸åŸå€¼ç›¸åŒï¼‰")
            return []

        # æŒ‰é¢„æµ‹PCEä»é«˜åˆ°ä½æ’åº
        tested_values.sort(key=lambda x: x['pce'], reverse=True)

        # å–å‰Nä¸ªæœ€ä½³æ›¿ä»£å€¼
        best_alternatives = tested_values[:num_alternatives]

        print(f"  âœ… æ‰¾åˆ° {len(best_alternatives)} ä¸ªæœ€ä½³æ›¿ä»£å€¼:")
        for idx, alt in enumerate(best_alternatives):
            print(f"    {idx + 1}. '{alt['value']}' -> é¢„æµ‹PCE: {alt['pce']:.4f}% (æ”¹è¿›: {alt['improvement']:+.4f}%)")

        return best_alternatives

    def run_optimization(self, max_records=None, alternatives_per_feature=3):
        """è¿è¡Œä¼˜åŒ–è¿‡ç¨‹"""
        print("\n" + "=" * 60)
        print("ğŸ¯ BestNIPè®°å½•ç‰¹å¾ä¼˜åŒ– (é›†æˆæ¨¡å‹)")
        print("=" * 60)

        print("ğŸ“Š æ¨¡å‹é…ç½®:")
        for model_name, config in self.model_configs.items():
            if model_name in self.models:
                print(f"  {model_name.upper()}: RÂ²={config['r2']:.4f}, æƒé‡={self.weights[model_name]:.4f}")

        if self.bestnip_records is None or len(self.bestnip_records) == 0:
            print("âŒ BestNIPæ–‡ä»¶ä¸­æ²¡æœ‰è®°å½•")
            return

        # ç¡®å®šè¦å¤„ç†çš„è®°å½•æ•°é‡
        if max_records is not None:
            records_to_process = self.bestnip_records.head(max_records)
            print(f"ğŸ“Š å°†å¤„ç†å‰ {max_records} æ¡è®°å½•ï¼ˆå…± {len(self.bestnip_records)} æ¡ï¼‰")
        else:
            records_to_process = self.bestnip_records
            print(f"ğŸ“Š å°†å¤„ç†æ‰€æœ‰ {len(self.bestnip_records)} æ¡è®°å½•")

        print(f"ğŸ¯ æ¯ä¸ªç‰¹å¾å°†å¯»æ‰¾ {alternatives_per_feature} ä¸ªæœ€ä½³æ›¿ä»£å€¼")

        # å­˜å‚¨æ‰€æœ‰ç»“æœ
        all_results = []

        # å¯¹æ¯æ¡è®°å½•è¿›è¡Œä¼˜åŒ–
        for record_idx, (_, record) in enumerate(records_to_process.iterrows()):
            record_id = record.get('Record', f'Record_{record_idx + 1}')
            print(f"\nğŸ“Š å¤„ç†è®°å½• {record_idx + 1} (ID: {record_id})")

            record_results = {}

            # å¯¹æ¯ä¸ªç›®æ ‡ç‰¹å¾å¯»æ‰¾æ›¿ä»£å€¼
            for feature_name in self.target_features:
                alternatives = self.find_alternative_values(record_idx, record, feature_name, alternatives_per_feature)

                if alternatives:
                    record_results[feature_name] = {
                        'original_value': record.get(feature_name, ''),
                        'original_pce': record.get('PCE', 0),
                        'alternatives': alternatives
                    }

            all_results.append({
                'record_id': record_id,
                'original_record': record.to_dict(),
                'optimization_results': record_results
            })

        # ä¿å­˜ç»“æœ
        self.save_results(all_results)

        # ç”ŸæˆæŠ¥å‘Š
        self.generate_report(all_results)

        return all_results

    def save_results(self, all_results):
        """ä¿å­˜ä¼˜åŒ–ç»“æœ"""
        try:
            # åˆ›å»ºç»“æœDataFrame
            results_data = []

            for result_idx, result in enumerate(all_results):
                record_id = result['record_id']

                for feature_name, feature_result in result['optimization_results'].items():
                    original_value = feature_result['original_value']
                    original_pce = feature_result['original_pce']

                    for alt_idx, alternative in enumerate(feature_result['alternatives']):
                        results_data.append({
                            'Record_Index': result_idx + 1,
                            'Record_ID': record_id,
                            'Feature': feature_name,
                            'Alternative_Rank': alt_idx + 1,
                            'Original_Value': original_value,
                            'Alternative_Value': alternative['value'],
                            'Original_PCE': original_pce,
                            'Predicted_PCE': alternative['pce'],
                            'Improvement': alternative['improvement']
                        })

            # è½¬æ¢ä¸ºDataFrame
            results_df = pd.DataFrame(results_data)

            # ä¿å­˜åˆ°Excel
            filename = f"{self.results_dir}/bestnip_optimization_ensemble_{self.timestamp}.xlsx"
            results_df.to_excel(filename, index=False)
            print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜: {filename}")

            # åŒæ—¶ä¿å­˜ä¸ºCSVæ ¼å¼
            csv_filename = f"{self.results_dir}/bestnip_optimization_ensemble_{self.timestamp}.csv"
            results_df.to_csv(csv_filename, index=False, encoding='utf-8-sig')
            print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜ä¸ºCSV: {csv_filename}")

        except Exception as e:
            print(f"âŒ ä¿å­˜ç»“æœå¤±è´¥: {e}")

    def generate_report(self, all_results):
        """ç”Ÿæˆä¼˜åŒ–æŠ¥å‘Š"""
        try:
            report_content = []
            report_content.append("BestNIPè®°å½•ç‰¹å¾ä¼˜åŒ–æŠ¥å‘Š (é›†æˆæ¨¡å‹)")
            report_content.append("=" * 70)
            report_content.append(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            report_content.append(f"æ•°æ®åº“æ–‡ä»¶: {self.data_path}")
            report_content.append(f"ç›®æ ‡è®°å½•æ–‡ä»¶: {self.bestnip_path}")
            report_content.append(f"ä¼˜åŒ–ç‰¹å¾: {', '.join(self.target_features)}")

            report_content.append(f"\nğŸ“Š æ¨¡å‹é…ç½®:")
            for model_name, config in self.model_configs.items():
                if model_name in self.models:
                    report_content.append(
                        f"  {model_name.upper()}: RÂ²={config['r2']:.4f}, æƒé‡={self.weights[model_name]:.4f}")

            report_content.append("")

            report_content.append("ğŸ“Š ä¼˜åŒ–ç»“æœ:")
            report_content.append("-" * 70)

            for result_idx, result in enumerate(all_results):
                record_id = result['record_id']
                record_results = result['optimization_results']

                report_content.append(f"\nè®°å½• {result_idx + 1} (ID: {record_id}):")

                for feature_name, feature_result in record_results.items():
                    report_content.append(f"  {feature_name}:")
                    report_content.append(f"    åŸå§‹å€¼: '{feature_result['original_value']}'")
                    report_content.append(f"    åŸå§‹PCE: {feature_result['original_pce']:.2f}%")

                    for alt_idx, alternative in enumerate(feature_result['alternatives']):
                        report_content.append(f"    æ›¿ä»£å€¼{alt_idx + 1}: '{alternative['value']}'")
                        report_content.append(f"        é¢„æµ‹PCE: {alternative['pce']:.4f}%")
                        report_content.append(f"        æ”¹è¿›: {alternative['improvement']:+.4f}%")

                report_content.append("-" * 40)

            # ä¿å­˜æŠ¥å‘Š
            report_filename = f"{self.results_dir}/bestnip_optimization_report_ensemble_{self.timestamp}.txt"
            with open(report_filename, 'w', encoding='utf-8') as f:
                f.write('\n'.join(report_content))

            print(f"ğŸ“‹ ä¼˜åŒ–æŠ¥å‘Šå·²ä¿å­˜: {report_filename}")

            # æ‰“å°æŠ¥å‘Šæ‘˜è¦
            print("\n" + "=" * 60)
            print("ğŸ“Š ä¼˜åŒ–å®Œæˆ!")
            print("=" * 60)
            print(f"âœ… å·²å¤„ç† {len(all_results)} æ¡è®°å½•")
            print(f"âœ… æ¯ä¸ªç‰¹å¾æ‰¾åˆ°3ä¸ªæœ€ä½³æ›¿ä»£å€¼")
            print(f"âœ… ä½¿ç”¨é›†æˆæ¨¡å‹é¢„æµ‹ï¼ˆåŸºäºæµ‹è¯•é›†RÂ²åŠ æƒï¼‰")
            print(f"âœ… ç»“æœä¿å­˜åœ¨: {self.results_dir}/ ç›®å½•ä¸‹")

            # æ˜¾ç¤ºæœ€ä½³æ”¹è¿›
            print(f"\nğŸ† æœ€ä½³æ”¹è¿›æ€»ç»“:")

            all_improvements = []
            for result_idx, result in enumerate(all_results):
                for feature_name, feature_result in result['optimization_results'].items():
                    for alt_idx, alternative in enumerate(feature_result['alternatives']):
                        all_improvements.append({
                            'Record': result_idx + 1,
                            'Feature': feature_name,
                            'Alternative_Rank': alt_idx + 1,
                            'Alternative_Value': alternative['value'],
                            'Predicted_PCE': alternative['pce'],
                            'Improvement': alternative['improvement']
                        })

            # æŒ‰æ”¹è¿›å€¼æ’åº
            all_improvements.sort(key=lambda x: x['Improvement'], reverse=True)

            print("\nğŸ“ˆ å‰5ä¸ªæœ€ä½³æ”¹è¿›:")
            for i, imp in enumerate(all_improvements[:5]):
                print(f"{i + 1}. è®°å½•{imp['Record']}çš„{imp['Feature']}: "
                      f"'{imp['Alternative_Value']}' -> {imp['Predicted_PCE']:.4f}% "
                      f"(æ”¹è¿›: {imp['Improvement']:+.4f}%)")

        except Exception as e:
            print(f"âŒ ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {e}")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” BestNIPè®°å½•ç‰¹å¾ä¼˜åŒ–ç³»ç»Ÿ (é›†æˆæ¨¡å‹)")
    print("ğŸ¯ ç›®æ ‡: ä¼˜åŒ–bestnip.xlsxä¸­è®°å½•çš„ETL_Passivatorã€HTL_Passivatorå’ŒPrecursor_Solution_Addictive")
    print("ğŸ“Š æ–¹æ³•: ä½¿ç”¨é›†æˆæ¨¡å‹ï¼ˆRF, XGB, CatBoost, LGBMï¼‰åŠ æƒé¢„æµ‹")
    print("ğŸ“Š è¾“å‡º: æ¯ä¸ªç‰¹å¾æ‰¾åˆ°3ä¸ªæœ€ä½³æ›¿ä»£å€¼ï¼ˆä¸åŸå€¼ä¸åŒï¼‰")

    try:
        # åˆ›å»ºä¼˜åŒ–å™¨å®ä¾‹
        optimizer = BestNIPOptimizer(
            data_path="FinalDataAll.xlsx",
            bestnip_path="bestnip.xlsx"
        )

        # è¿è¡Œä¼˜åŒ– - å¯ä»¥æŒ‡å®šè¦å¤„ç†çš„è®°å½•æ•°é‡ï¼Œä¾‹å¦‚åªå¤„ç†å‰3æ¡ï¼šoptimizer.run_optimization(max_records=3)
        # æ¯ä¸ªç‰¹å¾å¯»æ‰¾3ä¸ªæœ€ä½³æ›¿ä»£å€¼
        results = optimizer.run_optimization(max_records=None, alternatives_per_feature=3)

    except FileNotFoundError as e:
        print(f"âŒ æ–‡ä»¶æœªæ‰¾åˆ°: {e}")
        print("ğŸ’¡ è¯·ç¡®ä¿ä»¥ä¸‹æ–‡ä»¶å­˜åœ¨:")
        print("   - models/best_rf_model.pkl (éšæœºæ£®æ—æ¨¡å‹)")
        print("   - models/best_xgb_model.pkl (XGBoostæ¨¡å‹)")
        print("   - models/best_catboost_model.pkl (CatBoostæ¨¡å‹)")
        print("   - models/best_lgbm_model.pkl (LightGBMæ¨¡å‹)")
        print("   - FinalDataAll.xlsx (æ•°æ®åº“æ–‡ä»¶)")
        print("   - bestnip.xlsx (ç›®æ ‡è®°å½•æ–‡ä»¶)")
    except Exception as e:
        print(f"âŒ ç¨‹åºæ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()