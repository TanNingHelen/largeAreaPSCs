import os
import pandas as pd
import numpy as np
from catboost import CatBoostRegressor, Pool
import shap
import warnings
import joblib
import xgboost as xgb
import lightgbm as lgb
from sklearn.ensemble import RandomForestRegressor

# é…ç½®è®¾ç½®
warnings.filterwarnings('ignore')

# æ¨¡å‹æƒé‡é…ç½®ï¼ˆåŸºäºæµ‹è¯•é›†RÂ²ï¼‰
model_configs = {
    'rf': {'path': 'models/best_rf_model.pkl', 'r2': 0.6892},
    'xgb': {'path': 'models/best_xgb_model.pkl', 'r2': 0.7630},
    'catboost': {'path': 'models/best_catboost_model.pkl', 'r2': 0.6762},
    'lgbm': {'path': 'models/best_lgbm_model.pkl', 'r2': 0.7446}
}

# åŠ è½½æ•°æ®
df = pd.read_excel("FinalDataAll.xlsx")
X = df.drop('PCE', axis=1)

# ä¿å­˜åŸå§‹åˆ—å
original_columns = X.columns.tolist()
X.columns = [col.replace(' ', '_') for col in X.columns]

# åŠ è½½æ‰€æœ‰æ¨¡å‹
print("åŠ è½½é›†æˆæ¨¡å‹...")
models = {}
weights = {}
successful_models = 0

# è®¡ç®—æ€»RÂ²ç”¨äºæƒé‡å½’ä¸€åŒ–
total_r2 = sum(config['r2'] for config in model_configs.values())

for model_name, config in model_configs.items():
    try:
        if model_name == 'catboost':
            # å°è¯•ç”¨joblibåŠ è½½æ¨¡å‹
            try:
                model = joblib.load(config['path'])
                print(f"âœ… CatBoostæ¨¡å‹ä» {config['path']} åŠ è½½æˆåŠŸ")
            except:
                # å°è¯•ç”¨CatBoostè‡ªå·±çš„åŠ è½½æ–¹æ³•
                model = CatBoostRegressor()
                model.load_model(config['path'])
                print(f"âœ… CatBoostæ¨¡å‹ä» {config['path']} åŠ è½½æˆåŠŸ (ä½¿ç”¨CatBooståŸç”Ÿæ ¼å¼)")

        elif model_name == 'xgb':
            # åŠ è½½XGBoostæ¨¡å‹
            model = joblib.load(config['path'])
            print(f"âœ… XGBoostæ¨¡å‹åŠ è½½æˆåŠŸ")

        elif model_name == 'lgbm':
            # åŠ è½½LightGBMæ¨¡å‹
            model = joblib.load(config['path'])
            print(f"âœ… LightGBMæ¨¡å‹åŠ è½½æˆåŠŸ")

        elif model_name == 'rf':
            # åŠ è½½RandomForestæ¨¡å‹
            model = joblib.load(config['path'])
            print(f"âœ… RandomForestæ¨¡å‹åŠ è½½æˆåŠŸ")

        models[model_name] = model
        # è®¡ç®—æƒé‡ï¼šè¯¥æ¨¡å‹RÂ²å æ€»RÂ²çš„æ¯”ä¾‹
        weights[model_name] = config['r2'] / total_r2
        successful_models += 1
        print(f"  {model_name.upper()}æƒé‡: {weights[model_name]:.4f}")

    except Exception as e:
        print(f"âŒ {model_name.upper()}æ¨¡å‹åŠ è½½å¤±è´¥: {e}")

# æ£€æŸ¥æ˜¯å¦æœ‰æ¨¡å‹æˆåŠŸåŠ è½½
if successful_models == 0:
    print("âŒ æ‰€æœ‰æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œæ— æ³•è¿›è¡Œåˆ†æ")
    exit(1)

print(f"\nâœ… æˆåŠŸåŠ è½½ {successful_models}/{len(model_configs)} ä¸ªæ¨¡å‹")
print("æ¨¡å‹æƒé‡æ±‡æ€»:")
for model_name, weight in weights.items():
    if model_name in models:
        print(f"  {model_name.upper()}: {weight:.4f}")

# è®¡ç®—é›†æˆæ¨¡å‹çš„åŠ æƒSHAPå€¼
print("\nè®¡ç®—é›†æˆæ¨¡å‹çš„åŠ æƒSHAPå€¼...")
weighted_shap_values = None
total_weight = 0

for model_name, model in models.items():
    try:
        print(f"è®¡ç®— {model_name.upper()} çš„SHAPå€¼...")

        # å‡†å¤‡ç‰¹å¾æ•°æ®
        X_features = X.copy()
        X_features.columns = original_columns

        if model_name == 'catboost':
            # å¯¹äºCatBoostï¼Œä½¿ç”¨Pool
            explainer = shap.TreeExplainer(model)
            shap_values = explainer.shap_values(Pool(X_features))
        elif model_name == 'xgb':
            # å¯¹äºXGBoost
            explainer = shap.TreeExplainer(model)
            shap_values = explainer.shap_values(X_features)
        elif model_name == 'lgbm':
            # å¯¹äºLightGBM
            explainer = shap.TreeExplainer(model)
            shap_values = explainer.shap_values(X_features)
        elif model_name == 'rf':
            # å¯¹äºRandomForest
            explainer = shap.TreeExplainer(model)
            shap_values = explainer.shap_values(X_features)

        # åŠ æƒSHAPå€¼
        model_weight = weights[model_name]
        if weighted_shap_values is None:
            weighted_shap_values = shap_values * model_weight
        else:
            weighted_shap_values += shap_values * model_weight

        total_weight += model_weight
        print(f"  {model_name.upper()} SHAPå€¼è®¡ç®—å®Œæˆï¼Œæƒé‡: {model_weight:.4f}")

    except Exception as e:
        print(f"  âŒ {model_name.upper()} SHAPå€¼è®¡ç®—å¤±è´¥: {e}")

# å½’ä¸€åŒ–åŠ æƒSHAPå€¼
if weighted_shap_values is not None:
    weighted_shap_values /= total_weight
    print("\nâœ… é›†æˆæ¨¡å‹SHAPå€¼è®¡ç®—å®Œæˆ")
else:
    print("âŒ æ‰€æœ‰æ¨¡å‹çš„SHAPå€¼è®¡ç®—éƒ½å¤±è´¥äº†")
    exit(1)

# æŸ¥æ‰¾FAç‰¹å¾
print("\næŸ¥æ‰¾FAç‰¹å¾...")
fa_columns = []
for col in original_columns:
    if 'FA' in col.upper():
        fa_columns.append(col)

if not fa_columns:
    print("æœªæ‰¾åˆ°FAç‰¹å¾åˆ—ï¼Œå°è¯•æŸ¥æ‰¾å…¶ä»–å¯èƒ½çš„åç§°...")
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œå°è¯•å…¶ä»–å¯èƒ½çš„FAç›¸å…³åˆ—å
    for col in X.columns:
        if 'FA' in col.upper():
            # æ‰¾åˆ°å¯¹åº”çš„åŸå§‹åˆ—å
            idx = list(X.columns).index(col)
            if idx < len(original_columns):
                fa_columns.append(original_columns[idx])

if not fa_columns:
    print("ä»æœªæ‰¾åˆ°FAç‰¹å¾åˆ—ï¼Œè¯·æ£€æŸ¥æ•°æ®åˆ—å")
    exit()

print(f"æ‰¾åˆ°çš„FAç‰¹å¾: {fa_columns}")

# åˆ›å»ºè¾“å‡ºç›®å½•
os.makedirs("ensemble_results", exist_ok=True)

# åˆ†ææ¯ä¸ªFAç‰¹å¾
for fa_original in fa_columns:
    print(f"\n{'=' * 50}")
    print(f"å¤„ç†ç‰¹å¾: {fa_original}")
    print(f"{'=' * 50}")

    # è·å–ç‰¹å¾ç´¢å¼•
    fa_idx = original_columns.index(fa_original)

    # è·å–ç‰¹å¾å¯¹åº”çš„ç»Ÿä¸€åˆ—å
    fa_col = fa_original.replace(' ', '_')

    # æå–é›†æˆSHAPå€¼
    ensemble_shap_values = weighted_shap_values[:, fa_idx]
    fa_values = X[fa_col].values

    # åˆ›å»ºç»“æœDataFrame
    result_df = pd.DataFrame({
        'FA_Value': fa_values,
        'Ensemble_SHAP_Value': ensemble_shap_values,
        'FA_Feature': fa_original
    })

    # æŒ‰FAå€¼ä»å°åˆ°å¤§æ’åº
    result_df = result_df.sort_values('FA_Value')

    # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
    unique_values = result_df['FA_Value'].nunique()
    shap_mean = result_df['Ensemble_SHAP_Value'].mean()
    shap_std = result_df['Ensemble_SHAP_Value'].std()

    # ä¿å­˜åˆ°CSV
    csv_file = f"ensemble_results/Ensemble_FA_{fa_col}_SHAP_Values.csv"
    result_df.to_csv(csv_file, index=False)

    print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
    print(f"  FAå”¯ä¸€å€¼æ•°é‡: {unique_values}")
    print(f"  å¹³å‡SHAPå€¼: {shap_mean:.6f}")
    print(f"  SHAPå€¼æ ‡å‡†å·®: {shap_std:.6f}")
    print(f"  SHAPå€¼èŒƒå›´: [{result_df['Ensemble_SHAP_Value'].min():.6f}, {result_df['Ensemble_SHAP_Value'].max():.6f}]")

    print(f"\nğŸ’¾ å·²ä¿å­˜åˆ°æ–‡ä»¶: {csv_file}")
    print(f"  æ•°æ®è¡Œæ•°: {len(result_df)}")

    print(f"\nğŸ“‹ å‰10è¡Œæ•°æ®:")
    print(result_df.head(10).to_string(index=False))

    print(f"\nğŸ“‹ å10è¡Œæ•°æ®:")
    print(result_df.tail(10).to_string(index=False))

# ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
print(f"\n{'=' * 60}")
print("ENSEMBLE SHAPåˆ†ææŠ¥å‘Š")
print(f"{'=' * 60}")
print(f"âœ… åˆ†æçš„FAç‰¹å¾æ•°é‡: {len(fa_columns)}")
print(f"âœ… ä½¿ç”¨çš„æ¨¡å‹æ•°é‡: {successful_models}")
print(f"âœ… æ¨¡å‹æƒé‡: {weights}")

# ä¿å­˜æ¨¡å‹æƒé‡ä¿¡æ¯
weights_df = pd.DataFrame([
    {'Model': model_name.upper(),
     'R2_Score': model_configs[model_name]['r2'],
     'Weight': weight}
    for model_name, weight in weights.items()
])
weights_df.to_csv("ensemble_results/model_weights.csv", index=False)
print(f"ğŸ’¾ æ¨¡å‹æƒé‡ä¿¡æ¯å·²ä¿å­˜åˆ°: ensemble_results/model_weights.csv")

print(f"\nğŸ¯ é›†æˆæ¨¡å‹SHAPåˆ†æå®Œæˆï¼")
print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: ensemble_results/ ç›®å½•")
print(f"ğŸ“Š æ¯ä¸ªFAç‰¹å¾ç”Ÿæˆä¸€ä¸ªCSVæ–‡ä»¶ï¼ŒåŒ…å«FAå€¼å’Œé›†æˆSHAPå€¼")