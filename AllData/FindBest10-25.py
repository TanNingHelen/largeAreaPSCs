import pandas as pd
import os


class PCEAnalyzer:
    def __init__(self, data_path="FinalData10312All.xlsx", mapping_path="label_mappings/full_mapping_summary.csv"):
        self.data_path = data_path
        self.mapping_path = mapping_path
        # ä¸å†è®¾ç½®ç‰¹å®šçš„ç›®æ ‡æ¡ä»¶ï¼Œå¯»æ‰¾æ‰€æœ‰ç»“æž„ä¸­çš„é«˜æ•ˆæ•°æ®
        self.df = None
        self.all_mappings = {}  # å­˜å‚¨æ‰€æœ‰å­—æ®µçš„æ˜ å°„

        self.load_data()
        self.load_all_mappings()  # åŠ è½½æ‰€æœ‰å­—æ®µçš„æ˜ å°„

    def load_data(self):
        """åŠ è½½æ•°æ®ï¼ˆç¡®ä¿æ‰€æœ‰ç‰¹å¾éƒ½æ˜¯æ•°å€¼ç±»åž‹ï¼‰"""
        try:
            self.df = pd.read_excel(self.data_path)
            print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸï¼Œæ€»è®°å½•æ•°: {len(self.df)}")
            print("ðŸ“Š æ•°æ®å­—æ®µ:", list(self.df.columns))

            # æ£€æŸ¥Active_Areaåˆ—æ˜¯å¦å­˜åœ¨
            if 'Active_Area' not in self.df.columns:
                print("âš ï¸ è­¦å‘Š: æ•°æ®é›†ä¸­æ²¡æœ‰æ‰¾åˆ°Active_Areaå­—æ®µ")

        except Exception as e:
            print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
            raise

    def load_all_mappings(self):
        """åŠ è½½æ‰€æœ‰å­—æ®µçš„æ˜ å°„ï¼ˆä¸ä»…ä»…æ˜¯ç›®æ ‡ç‰¹å¾ï¼‰"""
        if not os.path.exists(self.mapping_path):
            print(f"âš ï¸ æ˜ å°„æ–‡ä»¶æœªæ‰¾åˆ°: {self.mapping_path}")
            print("âš ï¸ å°†ç›´æŽ¥ä½¿ç”¨ç¼–ç å€¼æ˜¾ç¤ºæ•°æ®")
            return

        try:
            mapping_df = pd.read_csv(self.mapping_path)
            for feature in mapping_df['Feature'].unique():
                self.all_mappings[feature] = {
                    'original_to_encoded': {},
                    'encoded_to_original': {}
                }
                feature_data = mapping_df[mapping_df['Feature'] == feature]

                for _, row in feature_data.iterrows():
                    # åŒå‘æ˜ å°„
                    self.all_mappings[feature]['original_to_encoded'][row['Original']] = row['Encoded']
                    self.all_mappings[feature]['encoded_to_original'][row['Encoded']] = row['Original']
            print("âœ… æ‰€æœ‰å­—æ®µæ˜ å°„åŠ è½½æˆåŠŸ")
        except Exception as e:
            print(f"âŒ æ˜ å°„æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")

    def decode_feature(self, feature_name, encoded_value):
        """å°†ç¼–ç å€¼è½¬æ¢å›žåŽŸå§‹å€¼"""
        if feature_name in self.all_mappings:
            # å¤„ç†NaNå€¼
            if pd.isna(encoded_value):
                return "N/A"
            # ç¡®ä¿encoded_valueæ˜¯æ•´æ•°ç±»åž‹
            try:
                encoded_int = int(encoded_value)
                return self.all_mappings[feature_name]['encoded_to_original'].get(encoded_int, str(encoded_value))
            except (ValueError, TypeError):
                return str(encoded_value)
        return encoded_value  # å¦‚æžœæ²¡æœ‰æ˜ å°„ï¼Œç›´æŽ¥è¿”å›žå€¼

    def find_top_records(self, n=20):
        """å¯»æ‰¾é¢ç§¯åœ¨10-25å¹³æ–¹åŽ˜ç±³çš„é«˜æ•ˆæ•°æ®"""
        # æ£€æŸ¥Active_Areaåˆ—æ˜¯å¦å­˜åœ¨
        if 'Active_Area' not in self.df.columns:
            print("âŒ é”™è¯¯: æ•°æ®é›†ä¸­æ²¡æœ‰Active_Areaå­—æ®µ")
            return pd.DataFrame()

        # æ£€æŸ¥PCEåˆ—æ˜¯å¦å­˜åœ¨
        if 'PCE' not in self.df.columns:
            print("âŒ é”™è¯¯: æ•°æ®é›†ä¸­æ²¡æœ‰PCEå­—æ®µ")
            return pd.DataFrame()

        # ç­›é€‰é¢ç§¯åœ¨10-25å¹³æ–¹åŽ˜ç±³çš„è®°å½•
        area_filtered = self.df[
            (self.df['Active_Area'] >= 10) &
            (self.df['Active_Area'] <= 25)
            ]

        print(f"ðŸ“Š é¢ç§¯åœ¨10-25å¹³æ–¹åŽ˜ç±³çš„è®°å½•æ•°: {len(area_filtered)}")

        if len(area_filtered) == 0:
            print("âš ï¸ æ²¡æœ‰æ‰¾åˆ°é¢ç§¯åœ¨10-25å¹³æ–¹åŽ˜ç±³çš„è®°å½•")
            # æ˜¾ç¤ºé¢ç§¯çš„èŒƒå›´ï¼Œå¸®åŠ©ç”¨æˆ·äº†è§£æ•°æ®
            if 'Active_Area' in self.df.columns:
                print(
                    f"ðŸ“ æ•°æ®é›†ä¸­Active_Areaçš„èŒƒå›´: {self.df['Active_Area'].min():.2f} - {self.df['Active_Area'].max():.2f}")
            return pd.DataFrame()

        # æŒ‰PCEé™åºæŽ’åˆ—ï¼Œå–å‰nä¸ª
        result = area_filtered.nlargest(n, 'PCE').copy()

        return result

    def print_full_results(self, result_df):
        """æ‰“å°å®Œæ•´ç»“æžœï¼ˆæ‰€æœ‰å­—æ®µçš„åŽŸå§‹å€¼ï¼‰"""
        if result_df.empty:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„è®°å½•")
            return

        print(f"\n{'=' * 60}")
        print(f"ðŸ” æœç´¢ç»“æžœ: é¢ç§¯åœ¨10-25å¹³æ–¹åŽ˜ç±³çš„é«˜æ•ˆæ•°æ®")
        print(f"ðŸ“ Active_AreaèŒƒå›´: [10, 25] å¹³æ–¹åŽ˜ç±³")
        print(f"ðŸ“ˆ æ‰¾åˆ° {len(result_df)} æ¡è®°å½•ï¼ŒæŒ‰PCEé™åºæŽ’åˆ—:\n")

        for i, (idx, row) in enumerate(result_df.iterrows(), 1):
            print(f"ðŸ† ç¬¬{i}å (PCE: {row['PCE']:.2f}%, é¢ç§¯: {row['Active_Area']:.2f} cmÂ²)")

            # å®šä¹‰éœ€è¦æ˜¾ç¤ºçš„é‡è¦å­—æ®µï¼ˆæŒ‰ä¼˜å…ˆçº§æŽ’åºï¼‰
            important_fields = [
                'Record', 'PCE', 'Active_Area',
                'Structure', 'HTL', 'ETL', 'Perovskite',
                'Jsc', 'Voc', 'FF', 'PCE_std',
                'HTL-2', 'ETL-2', 'Metal_Electrode', 'Glass',
                'Precursor_Solution', 'Deposition_Method',
                'total_scribing_line_width(Î¼m)', 'P1Width(Î¼m)', 'P2Width(Î¼m)', 'P3Width(Î¼m)',
                'P1_P2Scribing_Spacing(Î¼m)', 'P2_P3Scribing_Spacing(Î¼m)',
                'GFF', 'submodule_number', 'Type'
            ]

            # æ˜¾ç¤ºé‡è¦å­—æ®µ
            for col in important_fields:
                if col in result_df.columns:
                    if col in self.all_mappings:  # æœ‰æ˜ å°„çš„å­—æ®µ
                        original_val = self.decode_feature(col, row[col])
                        print(f"  {col}: {original_val}")
                    else:  # æ•°å€¼å­—æ®µ
                        val = row[col]
                        if pd.isna(val):
                            print(f"  {col}: N/A")
                        else:
                            print(f"  {col}: {val}")

            print(f"{'-' * 60}")

    def analyze_results(self, result_df):
        """åˆ†æžç»“æžœæ•°æ®çš„ç»Ÿè®¡ä¿¡æ¯"""
        if result_df.empty:
            return

        print(f"\nðŸ“Š æœç´¢ç»“æžœç»Ÿè®¡ä¿¡æ¯:")
        print(f"{'=' * 60}")

        # åŸºæœ¬ç»Ÿè®¡
        print(f"ðŸ“ˆ PCEç»Ÿè®¡:")
        print(f"  - å¹³å‡å€¼: {result_df['PCE'].mean():.2f}%")
        print(f"  - æœ€å¤§å€¼: {result_df['PCE'].max():.2f}%")
        print(f"  - æœ€å°å€¼: {result_df['PCE'].min():.2f}%")
        print(f"  - æ ‡å‡†å·®: {result_df['PCE'].std():.2f}%")

        # é¢ç§¯ç»Ÿè®¡
        print(f"\nðŸ“ é¢ç§¯ç»Ÿè®¡:")
        print(f"  - å¹³å‡é¢ç§¯: {result_df['Active_Area'].mean():.2f} cmÂ²")
        print(f"  - é¢ç§¯èŒƒå›´: {result_df['Active_Area'].min():.2f} - {result_df['Active_Area'].max():.2f} cmÂ²")

        # ç»“æž„åˆ†å¸ƒï¼ˆå¦‚æžœå­˜åœ¨Structureå­—æ®µï¼‰
        if 'Structure' in result_df.columns:
            print(f"\nðŸ—ï¸ ç»“æž„ç±»åž‹åˆ†å¸ƒ:")
            if 'Structure' in self.all_mappings:
                # è§£ç ç»“æž„ç±»åž‹
                structures = result_df['Structure'].apply(lambda x: self.decode_feature('Structure', x))
            else:
                structures = result_df['Structure']

            structure_counts = structures.value_counts()
            for structure, count in structure_counts.items():
                percentage = (count / len(result_df)) * 100
                print(f"  - {structure}: {count} æ¡ ({percentage:.1f}%)")

        # HTLåˆ†å¸ƒï¼ˆå¦‚æžœå­˜åœ¨HTLå­—æ®µï¼‰
        if 'HTL' in result_df.columns and 'HTL' in self.all_mappings:
            print(f"\nðŸ”„ HTLææ–™åˆ†å¸ƒ:")
            htl_types = result_df['HTL'].apply(lambda x: self.decode_feature('HTL', x))
            htl_counts = htl_types.value_counts()
            for htl, count in htl_counts.head(5).items():  # æ˜¾ç¤ºå‰5ç§
                percentage = (count / len(result_df)) * 100
                print(f"  - {htl}: {count} æ¡ ({percentage:.1f}%)")

        # ETLåˆ†å¸ƒï¼ˆå¦‚æžœå­˜åœ¨ETLå­—æ®µï¼‰
        if 'ETL' in result_df.columns and 'ETL' in self.all_mappings:
            print(f"\nðŸ”„ ETLææ–™åˆ†å¸ƒ:")
            etl_types = result_df['ETL'].apply(lambda x: self.decode_feature('ETL', x))
            etl_counts = etl_types.value_counts()
            for etl, count in etl_counts.head(5).items():  # æ˜¾ç¤ºå‰5ç§
                percentage = (count / len(result_df)) * 100
                print(f"  - {etl}: {count} æ¡ ({percentage:.1f}%)")


if __name__ == "__main__":
    try:
        print("ðŸ” å¼€å§‹æœç´¢é¢ç§¯åœ¨10-25å¹³æ–¹åŽ˜ç±³çš„é«˜æ•ˆé’™é’›çŸ¿å¤ªé˜³èƒ½ç”µæ± æ•°æ®...")
        analyzer = PCEAnalyzer(data_path="FinalData10312All.xlsx")

        # å¯»æ‰¾å‰20ä¸ªé«˜æ•ˆè®°å½•
        top_records = analyzer.find_top_records(n=20)

        if not top_records.empty:
            # æ‰“å°ç»“æžœ
            analyzer.print_full_results(top_records)

            # åˆ†æžç»“æžœç»Ÿè®¡ä¿¡æ¯
            analyzer.analyze_results(top_records)

            # ä¿å­˜ç»“æžœåˆ°Excelæ–‡ä»¶
            output_df = top_records.copy()

            # ä¸ºæœ‰æ˜ å°„çš„å­—æ®µæ·»åŠ åŽŸå§‹å€¼åˆ—
            for col in output_df.columns:
                if col in analyzer.all_mappings:
                    # åˆ›å»ºæ–°åˆ—ï¼ŒåŒ…å«åŽŸå§‹å€¼
                    new_col_name = f"{col}_åŽŸå§‹å€¼"
                    output_df[new_col_name] = output_df[col].apply(
                        lambda x: analyzer.decode_feature(col, x)
                    )

            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            output_dir = "pce_predict"
            os.makedirs(output_dir, exist_ok=True)

            # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
            output_filename = os.path.join(output_dir, "top_high_pce_records_area_10-25.xlsx")
            output_df.to_excel(output_filename, index=False)
            print(f"\nðŸ’¾ ç»“æžœå·²ä¿å­˜åˆ°: {output_filename}")

            # åˆ›å»ºç®€åŒ–çš„ç»“æžœæ–‡ä»¶ï¼ˆåªåŒ…å«é‡è¦å­—æ®µï¼‰
            important_columns = [
                'Record', 'PCE', 'Active_Area', 'Structure', 'HTL', 'ETL',
                'Perovskite', 'Jsc', 'Voc', 'FF', 'GFF', 'total_scribing_line_width(Î¼m)'
            ]

            # åªä¿ç•™å®žé™…å­˜åœ¨çš„åˆ—
            available_columns = [col for col in important_columns if col in output_df.columns]
            simplified_df = output_df[available_columns].copy()

            # ä¸ºç®€åŒ–æ–‡ä»¶ä¸­çš„å­—æ®µæ·»åŠ åŽŸå§‹å€¼
            for col in ['Structure', 'HTL', 'ETL']:
                if col in simplified_df.columns and col in analyzer.all_mappings:
                    original_col = f"{col}_åŽŸå§‹å€¼"
                    if original_col in output_df.columns:
                        simplified_df[original_col] = output_df[original_col]

            simplified_filename = os.path.join(output_dir, "simplified_top_records.xlsx")
            simplified_df.to_excel(simplified_filename, index=False)
            print(f"ðŸ’¾ ç®€åŒ–ç»“æžœå·²ä¿å­˜åˆ°: {simplified_filename}")

        else:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„è®°å½•")

    except FileNotFoundError as e:
        print(f"âŒ æ–‡ä»¶æœªæ‰¾åˆ°é”™è¯¯: {e}")
        print("ðŸ’¡ è¯·ç¡®ä¿ä»¥ä¸‹æ–‡ä»¶å­˜åœ¨:")
        print("   1. FinalData10312All.xlsx (ä¸»æ•°æ®æ–‡ä»¶)")
        print("   2. label_mappings/full_mapping_summary.csv (æ˜ å°„æ–‡ä»¶ï¼Œå¯é€‰)")
    except Exception as e:
        print(f"âŒ ç¨‹åºæ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºçŽ°é”™è¯¯: {str(e)}")
        import traceback

        traceback.print_exc()